{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reasoning {Vision} - Pretrained_models_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajr141/experiments/blob/master/Reasoning/Reasoning%20%7BVision%7D%20-%20Pretrained_models_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwhAO931Q2qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4d9a7bb3-c949-4647-980f-9213f216bf8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(r'/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BncN-vtjSIVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nwEgXDQRzuk",
        "colab_type": "text"
      },
      "source": [
        "## Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkt-IN26Q8zk",
        "colab_type": "text"
      },
      "source": [
        "<font face=\"Charis SIL\">The objective of this exercise is to demonstrate how can we use pretrained models on simple classification tasks. \n",
        "\n",
        "Here we will download famous models and will train the models on classification task and will see their output</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy3mJOmBR-Uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae3a187f-a33d-4bed-9deb-a09c918ca12d"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications import resnet50\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPFr4QHBhSNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "78aade5d-a51b-4508-81a2-3fa0ae9df8ca"
      },
      "source": [
        "!wget https://static.independent.co.uk/s3fs-public/thumbnails/image/2018/03/18/15/billgates.jpg?width=668"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 11:30:36--  https://static.independent.co.uk/s3fs-public/thumbnails/image/2018/03/18/15/billgates.jpg?width=668\n",
            "Resolving static.independent.co.uk (static.independent.co.uk)... 151.101.1.184, 151.101.65.184, 151.101.129.184, ...\n",
            "Connecting to static.independent.co.uk (static.independent.co.uk)|151.101.1.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23093 (23K) [image/jpeg]\n",
            "Saving to: ‘billgates.jpg?width=668’\n",
            "\n",
            "\rbillgates.jpg?width   0%[                    ]       0  --.-KB/s               \rbillgates.jpg?width 100%[===================>]  22.55K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-12-23 11:30:36 (2.21 MB/s) - ‘billgates.jpg?width=668’ saved [23093/23093]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqa648d0jgfg",
        "colab_type": "text"
      },
      "source": [
        "## Pretrained Models\n",
        "\n",
        "https://keras.io/applications/\n",
        "\n",
        "<font face=\"Charis SIL\">\n",
        "\n",
        "*   Xception\n",
        "*   VGG16\n",
        "*   VGG19\n",
        "*   ResNet\n",
        "*   ResNetV2\n",
        "*   InceptionV3\n",
        "*   InceptionResNetV2\n",
        "*   MobileNet\n",
        "*   MobileNetV2\n",
        "*   DenseNet\n",
        "*   NASNet\n",
        "\n",
        "Lets pick one and see what can we do with it, all the other models exposes a similar interface of use.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI5woHnKjbrz",
        "colab_type": "text"
      },
      "source": [
        "### Resnet 50\n",
        "\n",
        "When trying to run with tensorflow-2.0.0 below error<br>\n",
        "\n",
        "<font color='red'>\n",
        "RuntimeError: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRtIPrzkmxG-",
        "colab_type": "text"
      },
      "source": [
        "<b>Predict using existing model</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAVf8S-noE69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = 'billgates.jpg?width=668'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)  # Add 4th Dimention appering at axis 0\n",
        "'''preprocess_input - transforming from [0-255] scale to other scale, which can contain -ve values\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py'''\n",
        "x = resnet50.preprocess_input(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YNWniadg_fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cba2607-1a51-45b3-a0b0-fd67aa810665"
      },
      "source": [
        "model = resnet50.ResNet50(weights='imagenet')\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', resnet50.decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "Predicted: [('n04350905', 'suit', 0.75385237), ('n04591157', 'Windsor_tie', 0.09281588), ('n02865351', 'bolo_tie', 0.023333998)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQRCWIpbnSbF",
        "colab_type": "text"
      },
      "source": [
        "<b>Features only</b>\n",
        "\n",
        "We can freeze fully connected layers to include output from VGG Convolution only\n",
        "\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE6XNjaFm7Vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3ec72bd1-90c9-40c5-f5b6-205d9d9c3cbb"
      },
      "source": [
        "model = resnet50.ResNet50(weights='imagenet', include_top=False)\n",
        "features = model.predict(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Features shape:\", features.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (1, 224, 224, 3)\n",
            "Features shape: (1, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyw10CRWonES",
        "colab_type": "text"
      },
      "source": [
        "<b>Retrain on custom dataset - using all convolution layers</b>\n",
        "\n",
        "We will freeze the convolution layers and will train fully connected layers on new dataset\n",
        "\n",
        "Lets download mnist dataset and convert it into a format "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVWLcGs9124P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54a1a43f-8f91-4c42-e682-6c51faa379bf"
      },
      "source": [
        "import cv2\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "num_classes = 10\n",
        "# x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "# Convert 1D to 3D\n",
        "x_train = np.stack((x_train,)*3, axis=-1)\n",
        "x_test = np.stack((x_test,)*3, axis=-1)\n",
        "\n",
        "x_train = np.array([cv2.resize(image, (32, 32)) for image in x_train])\n",
        "x_test = np.array([cv2.resize(image, (32, 32)) for image in x_test])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(60000, 32, 32, 3) (60000, 10) (10000, 32, 32, 3) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh10NslUKmwr",
        "colab_type": "text"
      },
      "source": [
        "We are going to import a pretrained model by passing weights='imagenet'. Then we are going to change the input tensor size in model so that our data which is 28x28x3 can be fed and trained, otherwise we need to resize our dataset accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkZEhEaDol13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.input_layer import Input\n",
        "from keras.applications import vgg16\n",
        "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3))) \n",
        "# base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))  # Changing the input shape of model ideally its different"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufw5sgLszr0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Below we will be  freezing all the base model layers, so that cannot be retrained.\n",
        "We can choose which layers we want to train and not train by setting the trainable flag. '''\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    # print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_hAiU_Ao7GA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1a6a9392-7b24-413a-e8ea-d74facf8c201"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=1024, epochs=2, verbose=1, validation_data=(x_test, y_test)) \n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 720s 12ms/step - loss: 3.7777 - acc: 0.6902 - val_loss: 3.2492 - val_acc: 0.7665\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 717s 12ms/step - loss: 3.2576 - acc: 0.7703 - val_loss: 3.2046 - val_acc: 0.7754\n",
            "10000/10000 [==============================] - 110s 11ms/step\n",
            "Test loss: 3.204621992492676\n",
            "Test accuracy: 0.7754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti53XqOUOhjN",
        "colab_type": "text"
      },
      "source": [
        "<i>!!!!!!!! Hmm the accuracy is really bad, but we were able to ran the code, we will fine tune it later.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "och_0NGjSBgX",
        "colab_type": "text"
      },
      "source": [
        "<b>Retrain on custom dataset - using first few convolution layers</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZby-Q8svIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.input_layer import Input\n",
        "from keras.applications import vgg16\n",
        "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3))) \n",
        "# base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(28, 28, 3)))  # Changing the input shape of model ideally its different"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H96f9cv8s4Ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9dbd386c-5440-400d-aee8-d2fee079c755"
      },
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    print(layer.name)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_7\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAfvpq0jtgoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "81f88958-f166-45d6-b84d-2b7abf7f450c"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.get_layer('block3_pool').output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=1024, epochs=2, verbose=1, validation_data=(x_test, y_test)) \n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 456s 8ms/step - loss: 14.5423 - acc: 0.0977 - val_loss: 14.5353 - val_acc: 0.0982\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 454s 8ms/step - loss: 14.5487 - acc: 0.0974 - val_loss: 14.5353 - val_acc: 0.0982\n",
            "10000/10000 [==============================] - 68s 7ms/step\n",
            "Test loss: 14.535298265075683\n",
            "Test accuracy: 0.0982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTyIVeRBGCwD",
        "colab_type": "text"
      },
      "source": [
        "!!!! So by clipping the last few layers our scores are increased"
      ]
    }
  ]
}